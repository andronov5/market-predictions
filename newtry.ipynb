{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84263beb-49da-4c5e-94f4-c5bcb43d3ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06160b1-6281-4450-ad31-63a8ce9abfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded!!\n"
     ]
    }
   ],
   "source": [
    "from model.features import (\n",
    "    download_or_load_prices,\n",
    "    compute_features,\n",
    "    data_prep_and_feature_engineering,\n",
    ")\n",
    "from model.grid_search import run_grid_search\n",
    "from model.backtest import run_backtest\n",
    "\n",
    "print(\"downloaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f49524-c200-4086-b97e-51d6b477fbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\features.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  raw = yf.download(\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\features.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  raw = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "market columns -> ['SPY', '^VIX']\n"
     ]
    }
   ],
   "source": [
    "start = dt.date(2015, 1, 1)\n",
    "end   = dt.date(2024, 7, 1)\n",
    "\n",
    "# --- download SPY close prices ---\n",
    "spy = download_or_load_prices(\n",
    "    [\"SPY\"],\n",
    "    Path(\"spy_cache.parquet\"),\n",
    "    start,\n",
    "    end\n",
    ")[\"Close\"].rename(\"SPY\")\n",
    "\n",
    "# --- download ^VIX close prices ---\n",
    "vix = download_or_load_prices(\n",
    "    [\"^VIX\"],\n",
    "    Path(\"vix_cache.parquet\"),\n",
    "    start,\n",
    "    end\n",
    ")[\"Close\"].rename(\"^VIX\")\n",
    "\n",
    "# --- combine into one DataFrame with plain columns ---\n",
    "market = pd.concat([spy, vix], axis=1)\n",
    "\n",
    "print(\"market columns ->\", market.columns.tolist())   # should be ['SPY', '^VIX']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a8903df-e75b-4f81-9ecc-c8587c7afc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\features.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  raw = yf.download(\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\features.py:91: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"VIX_Change\"] = vix.pct_change(5)\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\features.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  lvl0 = pd.to_datetime(df.index.get_level_values(0), errors=\"coerce\")\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\features.py:27: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  raw = yf.download(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1860, 23) | y_train shape: (1860,)\n"
     ]
    }
   ],
   "source": [
    "# 1. raw prices for your ticker\n",
    "df_prices = download_or_load_prices(\n",
    "    [\"AAPL\"],\n",
    "    Path(\"price_cache.parquet\"),\n",
    "    start,\n",
    "    end\n",
    ")\n",
    "\n",
    "# 2. compute all features + target\n",
    "df_feat = compute_features(df_prices, market)\n",
    "\n",
    "# 3. build inputs for the next helper\n",
    "feature_list = [c for c in df_feat.columns if c != \"Target\"]  # list of feature names\n",
    "tickers      = [\"AAPL\"]                                       # list of tickers\n",
    "\n",
    "# 4. prepare training data (function returns X_train_sel, y_train)\n",
    "X_train, y_train = data_prep_and_feature_engineering(\n",
    "    tickers,\n",
    "    feature_list,\n",
    "    Path(\"feature_cache.parquet\"),\n",
    "    start,\n",
    "    end\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"| y_train shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4596f80e-c17f-411d-b382-34718a4869d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:13:54,384] A new study created in memory with name: no-name-5fcf16ee-ff7b-4b99-9ad5-c5255513b666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳  Running Optuna grid search (50 trials, CPU/GPU‑safe) …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:13:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:45: `gpu_id` is deprecated since2.0.0, use `device` instead. E.g. device=cpu/cuda/cuda:0\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:13:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:13:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:13:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004485 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.627489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:07,273] Trial 0 finished with value: 0.0 and parameters: {'n': 100, 'd': 13, 'leaf': 3, 'xgb_n': 400, 'xgb_lr': 0.03603652913973799, 'xgb_subsample': 0.5814318418339215, 'lgb_n': 250, 'lgb_lr': 0.0288432238641827, 'lgb_subsample': 0.7736652490153464}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003372 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.627631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:12,733] Trial 1 finished with value: 0.0 and parameters: {'n': 100, 'd': 5, 'leaf': 1, 'xgb_n': 100, 'xgb_lr': 0.02606555982451793, 'xgb_subsample': 0.8429640776896843, 'lgb_n': 100, 'lgb_lr': 0.026528058263151983, 'lgb_subsample': 0.9903794595741087}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004835 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's binary_logloss: 0.62736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:17,834] Trial 2 finished with value: 0.0 and parameters: {'n': 400, 'd': 14, 'leaf': 4, 'xgb_n': 150, 'xgb_lr': 0.048954005669499784, 'xgb_subsample': 0.5463633599118012, 'lgb_n': 200, 'lgb_lr': 0.010992060679152576, 'lgb_subsample': 0.6485428273416559}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003839 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_logloss: 0.627345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:22,493] Trial 3 finished with value: 0.0 and parameters: {'n': 500, 'd': 7, 'leaf': 4, 'xgb_n': 400, 'xgb_lr': 0.11411878221825769, 'xgb_subsample': 0.764410067283704, 'lgb_n': 200, 'lgb_lr': 0.014615097303647278, 'lgb_subsample': 0.9096093859401595}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004363 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_logloss: 0.627316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:27,532] Trial 4 finished with value: 0.0 and parameters: {'n': 300, 'd': 15, 'leaf': 3, 'xgb_n': 300, 'xgb_lr': 0.06642924535761928, 'xgb_subsample': 0.8237327330586239, 'lgb_n': 350, 'lgb_lr': 0.015034333467311171, 'lgb_subsample': 0.9127746949079578}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004730 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's binary_logloss: 0.627273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:32,671] Trial 5 finished with value: 0.0 and parameters: {'n': 400, 'd': 16, 'leaf': 3, 'xgb_n': 300, 'xgb_lr': 0.016153860010286708, 'xgb_subsample': 0.5574548541541133, 'lgb_n': 250, 'lgb_lr': 0.0100051459881844, 'lgb_subsample': 0.6507232393314384}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003560 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.627307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:37,197] Trial 6 finished with value: 0.0 and parameters: {'n': 300, 'd': 7, 'leaf': 4, 'xgb_n': 400, 'xgb_lr': 0.010441320909509779, 'xgb_subsample': 0.5289225149688923, 'lgb_n': 250, 'lgb_lr': 0.012044341627266865, 'lgb_subsample': 0.7645395689286634}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003748 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.626626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:42,030] Trial 7 finished with value: 0.0 and parameters: {'n': 500, 'd': 6, 'leaf': 1, 'xgb_n': 100, 'xgb_lr': 0.011920607230480738, 'xgb_subsample': 0.93180988559096, 'lgb_n': 300, 'lgb_lr': 0.0930698932477676, 'lgb_subsample': 0.8062900889121901}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004113 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.625558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:46,756] Trial 8 finished with value: 0.0 and parameters: {'n': 400, 'd': 7, 'leaf': 3, 'xgb_n': 200, 'xgb_lr': 0.21638599368213154, 'xgb_subsample': 0.9326416582360402, 'lgb_n': 500, 'lgb_lr': 0.11036743646312545, 'lgb_subsample': 0.8397981637316057}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003469 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.627547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:51,421] Trial 9 finished with value: 0.0 and parameters: {'n': 200, 'd': 17, 'leaf': 1, 'xgb_n': 450, 'xgb_lr': 0.08052114818583066, 'xgb_subsample': 0.8544333332064128, 'lgb_n': 500, 'lgb_lr': 0.05517007732932403, 'lgb_subsample': 0.8691930175555749}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004229 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.630142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:14:55,899] Trial 10 finished with value: 0.0 and parameters: {'n': 100, 'd': 20, 'leaf': 2, 'xgb_n': 500, 'xgb_lr': 0.030707787707296288, 'xgb_subsample': 0.6487538714226551, 'lgb_n': 400, 'lgb_lr': 0.29030969221820785, 'lgb_subsample': 0.5090053891070734}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003623 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:14:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.627376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:00,392] Trial 11 finished with value: 0.0 and parameters: {'n': 100, 'd': 11, 'leaf': 2, 'xgb_n': 250, 'xgb_lr': 0.02664878925239772, 'xgb_subsample': 0.6868869408047537, 'lgb_n': 100, 'lgb_lr': 0.030783283890979316, 'lgb_subsample': 0.9783505425149303}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004033 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.627398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:05,105] Trial 12 finished with value: 0.0 and parameters: {'n': 200, 'd': 11, 'leaf': 2, 'xgb_n': 350, 'xgb_lr': 0.02965020727158425, 'xgb_subsample': 0.6611258817540371, 'lgb_n': 100, 'lgb_lr': 0.030391738483502195, 'lgb_subsample': 0.6792389548066394}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003849 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.627602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:09,517] Trial 13 finished with value: 0.0 and parameters: {'n': 100, 'd': 11, 'leaf': 1, 'xgb_n': 100, 'xgb_lr': 0.02082429111912044, 'xgb_subsample': 0.7821378662290269, 'lgb_n': 150, 'lgb_lr': 0.027001488858631566, 'lgb_subsample': 0.9797761538175882}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.627766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:13,920] Trial 14 finished with value: 0.0 and parameters: {'n': 200, 'd': 9, 'leaf': 2, 'xgb_n': 200, 'xgb_lr': 0.04467901840337526, 'xgb_subsample': 0.874852422655027, 'lgb_n': 400, 'lgb_lr': 0.04842340455110089, 'lgb_subsample': 0.5238376605283598}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003721 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.627384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:18,614] Trial 15 finished with value: 0.0 and parameters: {'n': 100, 'd': 13, 'leaf': 3, 'xgb_n': 500, 'xgb_lr': 0.12275260662778482, 'xgb_subsample': 0.6094964420447804, 'lgb_n': 150, 'lgb_lr': 0.020035939547746556, 'lgb_subsample': 0.7184570022733534}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003662 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.627728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:23,212] Trial 16 finished with value: 0.0 and parameters: {'n': 200, 'd': 18, 'leaf': 1, 'xgb_n': 350, 'xgb_lr': 0.0424106356867145, 'xgb_subsample': 0.7337373729695167, 'lgb_n': 300, 'lgb_lr': 0.049566726248976845, 'lgb_subsample': 0.5587296625076347}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003870 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.6268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:27,710] Trial 17 finished with value: 0.0 and parameters: {'n': 100, 'd': 5, 'leaf': 2, 'xgb_n': 250, 'xgb_lr': 0.017990945567727738, 'xgb_subsample': 0.9714661322764659, 'lgb_n': 150, 'lgb_lr': 0.07861735450402847, 'lgb_subsample': 0.7701601202521702}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003726 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_logloss: 0.62737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:32,611] Trial 18 finished with value: 0.0 and parameters: {'n': 200, 'd': 9, 'leaf': 3, 'xgb_n': 400, 'xgb_lr': 0.2926253329249146, 'xgb_subsample': 0.6069946202033161, 'lgb_n': 200, 'lgb_lr': 0.021456064438529012, 'lgb_subsample': 0.5868906718479651}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003473 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.626452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:37,251] Trial 19 finished with value: 0.0 and parameters: {'n': 300, 'd': 9, 'leaf': 1, 'xgb_n': 150, 'xgb_lr': 0.03603734510796802, 'xgb_subsample': 0.7148612960055377, 'lgb_n': 100, 'lgb_lr': 0.17785508323522015, 'lgb_subsample': 0.9976547292875237}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003837 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.626755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:41,736] Trial 20 finished with value: 0.0 and parameters: {'n': 100, 'd': 13, 'leaf': 4, 'xgb_n': 450, 'xgb_lr': 0.02319136773651461, 'xgb_subsample': 0.8346161903009643, 'lgb_n': 400, 'lgb_lr': 0.03508317875897639, 'lgb_subsample': 0.895561059980995}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003502 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_logloss: 0.627461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:46,457] Trial 21 finished with value: 0.0 and parameters: {'n': 400, 'd': 14, 'leaf': 4, 'xgb_n': 150, 'xgb_lr': 0.05437833442924124, 'xgb_subsample': 0.5038040135575965, 'lgb_n': 200, 'lgb_lr': 0.023381093421814287, 'lgb_subsample': 0.6325890234746943}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003340 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_logloss: 0.627254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:50,859] Trial 22 finished with value: 0.0 and parameters: {'n': 400, 'd': 15, 'leaf': 4, 'xgb_n': 150, 'xgb_lr': 0.062018371931445083, 'xgb_subsample': 0.5808518086338731, 'lgb_n': 250, 'lgb_lr': 0.016010352269118847, 'lgb_subsample': 0.7262878400614643}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003795 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.62791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:15:55,469] Trial 23 finished with value: 0.0 and parameters: {'n': 300, 'd': 12, 'leaf': 3, 'xgb_n': 100, 'xgb_lr': 0.08414506805956871, 'xgb_subsample': 0.5489064800235302, 'lgb_n': 200, 'lgb_lr': 0.04025583977829588, 'lgb_subsample': 0.5935206682023063}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:15:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003824 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's binary_logloss: 0.627491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:00,005] Trial 24 finished with value: 0.0 and parameters: {'n': 500, 'd': 19, 'leaf': 4, 'xgb_n': 200, 'xgb_lr': 0.038814248573638736, 'xgb_subsample': 0.6300481076988611, 'lgb_n': 150, 'lgb_lr': 0.017042857674234538, 'lgb_subsample': 0.6861643199125778}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003015 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's binary_logloss: 0.627275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:04,746] Trial 25 finished with value: 0.0 and parameters: {'n': 400, 'd': 14, 'leaf': 3, 'xgb_n': 250, 'xgb_lr': 0.01372462977755105, 'xgb_subsample': 0.5020282761303785, 'lgb_n': 250, 'lgb_lr': 0.010311152015902166, 'lgb_subsample': 0.7997083506058484}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004265 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_logloss: 0.627471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:09,488] Trial 26 finished with value: 0.0 and parameters: {'n': 200, 'd': 16, 'leaf': 2, 'xgb_n': 150, 'xgb_lr': 0.048009313395709664, 'xgb_subsample': 0.8992451137814389, 'lgb_n': 100, 'lgb_lr': 0.02387239320689156, 'lgb_subsample': 0.9456024316423457}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003966 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.626794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:14,135] Trial 27 finished with value: 0.0 and parameters: {'n': 300, 'd': 10, 'leaf': 4, 'xgb_n': 100, 'xgb_lr': 0.030262308955586903, 'xgb_subsample': 0.7803926843648167, 'lgb_n': 350, 'lgb_lr': 0.059499471829637156, 'lgb_subsample': 0.6168084656614098}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003990 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.627906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:18,929] Trial 28 finished with value: 0.0 and parameters: {'n': 100, 'd': 12, 'leaf': 3, 'xgb_n': 350, 'xgb_lr': 0.021780622624946486, 'xgb_subsample': 0.5823673940237579, 'lgb_n': 150, 'lgb_lr': 0.04100040181662895, 'lgb_subsample': 0.8299592576627355}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003961 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.627189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:23,533] Trial 29 finished with value: 0.0 and parameters: {'n': 500, 'd': 14, 'leaf': 4, 'xgb_n': 450, 'xgb_lr': 0.07968830474677976, 'xgb_subsample': 0.6977484585051907, 'lgb_n': 200, 'lgb_lr': 0.01338429036848967, 'lgb_subsample': 0.7301155696281005}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004570 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's binary_logloss: 0.62743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:28,363] Trial 30 finished with value: 0.0 and parameters: {'n': 200, 'd': 8, 'leaf': 4, 'xgb_n': 200, 'xgb_lr': 0.178709258289375, 'xgb_subsample': 0.7544533282538358, 'lgb_n': 200, 'lgb_lr': 0.018259735386112544, 'lgb_subsample': 0.6923588105897887}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004125 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.627188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:33,093] Trial 31 finished with value: 0.0 and parameters: {'n': 500, 'd': 5, 'leaf': 4, 'xgb_n': 400, 'xgb_lr': 0.12490535799532373, 'xgb_subsample': 0.8255100162654857, 'lgb_n': 300, 'lgb_lr': 0.013400107463683423, 'lgb_subsample': 0.9350510134170672}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003872 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_logloss: 0.627293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:37,905] Trial 32 finished with value: 0.0 and parameters: {'n': 500, 'd': 6, 'leaf': 3, 'xgb_n': 350, 'xgb_lr': 0.06532761971043866, 'xgb_subsample': 0.7870399936448539, 'lgb_n': 250, 'lgb_lr': 0.01540196514200933, 'lgb_subsample': 0.9184451684564269}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004329 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's binary_logloss: 0.627272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:43,039] Trial 33 finished with value: 0.0 and parameters: {'n': 400, 'd': 7, 'leaf': 4, 'xgb_n': 300, 'xgb_lr': 0.14602436580458295, 'xgb_subsample': 0.756707853852736, 'lgb_n': 250, 'lgb_lr': 0.01001907040740836, 'lgb_subsample': 0.8780225540928113}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004049 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.627258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:47,879] Trial 34 finished with value: 0.0 and parameters: {'n': 400, 'd': 16, 'leaf': 4, 'xgb_n': 400, 'xgb_lr': 0.09058186353158951, 'xgb_subsample': 0.8081703997207137, 'lgb_n': 300, 'lgb_lr': 0.012558418272947134, 'lgb_subsample': 0.9349859182589828}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004210 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.627634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:52,528] Trial 35 finished with value: 0.0 and parameters: {'n': 500, 'd': 6, 'leaf': 3, 'xgb_n': 450, 'xgb_lr': 0.05200925602940008, 'xgb_subsample': 0.5634992223291164, 'lgb_n': 350, 'lgb_lr': 0.02648363639160473, 'lgb_subsample': 0.9641252878033988}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004660 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.627335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:16:57,352] Trial 36 finished with value: 0.0 and parameters: {'n': 300, 'd': 15, 'leaf': 3, 'xgb_n': 300, 'xgb_lr': 0.10063056523729812, 'xgb_subsample': 0.8909451343596414, 'lgb_n': 250, 'lgb_lr': 0.011768028208958907, 'lgb_subsample': 0.8537503570622601}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003940 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:16:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.627381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:02,330] Trial 37 finished with value: 0.0 and parameters: {'n': 400, 'd': 5, 'leaf': 4, 'xgb_n': 300, 'xgb_lr': 0.03452386804260346, 'xgb_subsample': 0.5466943290577785, 'lgb_n': 200, 'lgb_lr': 0.019914138489324447, 'lgb_subsample': 0.7819393809229498}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.006484 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.626741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:06,946] Trial 38 finished with value: 0.0 and parameters: {'n': 500, 'd': 8, 'leaf': 1, 'xgb_n': 100, 'xgb_lr': 0.014640852189867345, 'xgb_subsample': 0.8557817035529602, 'lgb_n': 150, 'lgb_lr': 0.06784878978099634, 'lgb_subsample': 0.6533087080788931}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004454 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.6268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:11,495] Trial 39 finished with value: 0.0 and parameters: {'n': 400, 'd': 7, 'leaf': 2, 'xgb_n': 400, 'xgb_lr': 0.024867227963802186, 'xgb_subsample': 0.6711042943770709, 'lgb_n': 300, 'lgb_lr': 0.03381966375099169, 'lgb_subsample': 0.821104817411822}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004318 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_logloss: 0.627368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:16,253] Trial 40 finished with value: 0.0 and parameters: {'n': 100, 'd': 10, 'leaf': 3, 'xgb_n': 500, 'xgb_lr': 0.017206229682658874, 'xgb_subsample': 0.9951489627056792, 'lgb_n': 100, 'lgb_lr': 0.014305813821464754, 'lgb_subsample': 0.8964380296467291}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004168 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.627341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:21,254] Trial 41 finished with value: 0.0 and parameters: {'n': 300, 'd': 17, 'leaf': 3, 'xgb_n': 250, 'xgb_lr': 0.06906200004383398, 'xgb_subsample': 0.8062750160241399, 'lgb_n': 350, 'lgb_lr': 0.011705035299625912, 'lgb_subsample': 0.9979657525748398}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.005515 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's binary_logloss: 0.627479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:26,082] Trial 42 finished with value: 0.0 and parameters: {'n': 300, 'd': 15, 'leaf': 3, 'xgb_n': 350, 'xgb_lr': 0.06937911884914406, 'xgb_subsample': 0.8389918159469539, 'lgb_n': 450, 'lgb_lr': 0.017270544170423698, 'lgb_subsample': 0.8563948214217104}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003948 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.627683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:30,817] Trial 43 finished with value: 0.0 and parameters: {'n': 100, 'd': 13, 'leaf': 2, 'xgb_n': 450, 'xgb_lr': 0.09899040506800626, 'xgb_subsample': 0.9317454945823741, 'lgb_n': 350, 'lgb_lr': 0.025719692803831944, 'lgb_subsample': 0.8977856312533354}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003749 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.627388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:35,637] Trial 44 finished with value: 0.0 and parameters: {'n': 200, 'd': 14, 'leaf': 3, 'xgb_n': 400, 'xgb_lr': 0.04128995105008829, 'xgb_subsample': 0.7279576230605846, 'lgb_n': 250, 'lgb_lr': 0.02019040603426233, 'lgb_subsample': 0.9659846118989375}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004172 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's binary_logloss: 0.627459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:40,178] Trial 45 finished with value: 0.0 and parameters: {'n': 500, 'd': 17, 'leaf': 2, 'xgb_n': 150, 'xgb_lr': 0.029463540245324875, 'xgb_subsample': 0.5273178092812969, 'lgb_n': 450, 'lgb_lr': 0.029346785488715596, 'lgb_subsample': 0.9178438789323791}. Best is trial 0 with value: 0.0.\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003964 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's binary_logloss: 0.627315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:44,568] Trial 46 finished with value: 0.0 and parameters: {'n': 100, 'd': 12, 'leaf': 1, 'xgb_n': 100, 'xgb_lr': 0.05754415987313669, 'xgb_subsample': 0.8765459958397048, 'lgb_n': 200, 'lgb_lr': 0.01196006501142099, 'lgb_subsample': 0.7923744529157865}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004138 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's binary_logloss: 0.627324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:49,130] Trial 47 finished with value: 0.0 and parameters: {'n': 200, 'd': 6, 'leaf': 4, 'xgb_n': 200, 'xgb_lr': 0.03417309686228145, 'xgb_subsample': 0.6397253540877559, 'lgb_n': 300, 'lgb_lr': 0.014916352125466785, 'lgb_subsample': 0.9555680469971347}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.003804 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's binary_logloss: 0.62649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:53,339] Trial 48 finished with value: 0.0 and parameters: {'n': 400, 'd': 11, 'leaf': 3, 'xgb_n': 350, 'xgb_lr': 0.11934263701217425, 'xgb_subsample': 0.9172028371085421, 'lgb_n': 150, 'lgb_lr': 0.10168026083544077, 'lgb_subsample': 0.9176424617092429}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "[LightGBM] [Info] Number of positive: 512, number of negative: 976\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 5865\n",
      "[LightGBM] [Info] Number of data points in the train set: 1488, number of used features: 23\n",
      "[LightGBM] [Info] Using GPU Device: gfx902, Vendor: Advanced Micro Devices, Inc.\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 23 dense feature groups (0.03 MB) transferred to GPU in 0.004147 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344086 -> initscore=-0.645138\n",
      "[LightGBM] [Info] Start training from score -0.645138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:19: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"n\", 100, 500, 100),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:29: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"xgb_n\", 100, 500, 50),\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:49: No visible GPU is found, setting device to CPU.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\context.cc:203: XGBoost is not compiled with CUDA support.\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\xgboost\\callback.py:386: UserWarning: [14:17:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  self.starting_round = model.num_boosted_rounds()\n",
      "C:\\Users\\17012\\Desktop\\market-predictions\\model\\grid_search.py:46: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  n_estimators=trial.suggest_int(\"lgb_n\", 100, 500, 50),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's binary_logloss: 0.627947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 14:17:57,739] Trial 49 finished with value: 0.0 and parameters: {'n': 100, 'd': 13, 'leaf': 2, 'xgb_n': 500, 'xgb_lr': 0.01964747816319229, 'xgb_subsample': 0.765638069000505, 'lgb_n': 400, 'lgb_lr': 0.03665491667852435, 'lgb_subsample': 0.5388532465338416}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed due to Must have at least 1 validation dataset for early stopping.; returning 0\n",
      "\n",
      "===== GridSearch Results (sorted by precision) =====\n",
      " value  params_d  params_leaf  params_lgb_lr  params_lgb_n  params_lgb_subsample  params_n  params_xgb_lr  params_xgb_n  params_xgb_subsample\n",
      "   0.0        13            3       0.028843           250              0.773665       100       0.036037           400              0.581432\n",
      "   0.0         5            4       0.019914           200              0.781939       400       0.034524           300              0.546694\n",
      "   0.0        10            4       0.059499           350              0.616808       300       0.030262           100              0.780393\n",
      "   0.0        12            3       0.041000           150              0.829959       100       0.021781           350              0.582367\n",
      "   0.0        14            4       0.013384           200              0.730116       500       0.079688           450              0.697748\n",
      "   0.0         8            4       0.018260           200              0.692359       200       0.178709           200              0.754453\n",
      "   0.0         5            4       0.013400           300              0.935051       500       0.124905           400              0.825510\n",
      "   0.0         6            3       0.015402           250              0.918445       500       0.065328           350              0.787040\n",
      "   0.0         7            4       0.010019           250              0.878023       400       0.146024           300              0.756708\n",
      "   0.0        16            4       0.012558           300              0.934986       400       0.090582           400              0.808170\n",
      "   0.0         6            3       0.026484           350              0.964125       500       0.052009           450              0.563499\n",
      "   0.0        15            3       0.011768           250              0.853750       300       0.100631           300              0.890945\n",
      "   0.0         8            1       0.067849           150              0.653309       500       0.014641           100              0.855782\n",
      "   0.0         5            1       0.026528           100              0.990379       100       0.026066           100              0.842964\n",
      "   0.0         7            2       0.033820           300              0.821105       400       0.024867           400              0.671104\n",
      "   0.0        10            3       0.014306           100              0.896438       100       0.017206           500              0.995149\n",
      "   0.0        17            3       0.011705           350              0.997966       300       0.069062           250              0.806275\n",
      "   0.0        15            3       0.017271           450              0.856395       300       0.069379           350              0.838992\n",
      "   0.0        13            2       0.025720           350              0.897786       100       0.098990           450              0.931745\n",
      "   0.0        14            3       0.020190           250              0.965985       200       0.041290           400              0.727958\n",
      "   0.0        17            2       0.029347           450              0.917844       500       0.029464           150              0.527318\n",
      "   0.0        12            1       0.011960           200              0.792374       100       0.057544           100              0.876546\n",
      "   0.0         6            4       0.014916           300              0.955568       200       0.034173           200              0.639725\n",
      "   0.0        11            3       0.101680           150              0.917642       400       0.119343           350              0.917203\n",
      "   0.0        16            2       0.023872           100              0.945602       200       0.048009           150              0.899245\n",
      "   0.0        14            3       0.010311           250              0.799708       400       0.013725           250              0.502028\n",
      "   0.0        19            4       0.017043           150              0.686164       500       0.038814           200              0.630048\n",
      "   0.0        12            3       0.040256           200              0.593521       300       0.084145           100              0.548906\n",
      "   0.0        14            4       0.010992           200              0.648543       400       0.048954           150              0.546363\n",
      "   0.0         7            4       0.014615           200              0.909609       500       0.114119           400              0.764410\n",
      "   0.0        15            3       0.015034           350              0.912775       300       0.066429           300              0.823733\n",
      "   0.0        16            3       0.010005           250              0.650723       400       0.016154           300              0.557455\n",
      "   0.0         7            4       0.012044           250              0.764540       300       0.010441           400              0.528923\n",
      "   0.0         6            1       0.093070           300              0.806290       500       0.011921           100              0.931810\n",
      "   0.0         7            3       0.110367           500              0.839798       400       0.216386           200              0.932642\n",
      "   0.0        17            1       0.055170           500              0.869193       200       0.080521           450              0.854433\n",
      "   0.0        20            2       0.290310           400              0.509005       100       0.030708           500              0.648754\n",
      "   0.0        11            2       0.030783           100              0.978351       100       0.026649           250              0.686887\n",
      "   0.0        11            2       0.030392           100              0.679239       200       0.029650           350              0.661126\n",
      "   0.0        11            1       0.027001           150              0.979776       100       0.020824           100              0.782138\n",
      "   0.0         9            2       0.048423           400              0.523838       200       0.044679           200              0.874852\n",
      "   0.0        13            3       0.020036           150              0.718457       100       0.122753           500              0.609496\n",
      "   0.0        18            1       0.049567           300              0.558730       200       0.042411           350              0.733737\n",
      "   0.0         5            2       0.078617           150              0.770160       100       0.017991           250              0.971466\n",
      "   0.0         9            3       0.021456           200              0.586891       200       0.292625           400              0.606995\n",
      "   0.0         9            1       0.177855           100              0.997655       300       0.036037           150              0.714861\n",
      "   0.0        13            4       0.035083           400              0.895561       100       0.023191           450              0.834616\n",
      "   0.0        14            4       0.023381           200              0.632589       400       0.054378           150              0.503804\n",
      "   0.0        15            4       0.016010           250              0.726288       400       0.062018           150              0.580852\n",
      "   0.0        13            2       0.036655           400              0.538853       100       0.019647           500              0.765638\n",
      "\n",
      "Grid search completed. Results saved to grid_search_results.parquet\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# hyper‑parameter search\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m best_params, best_model = run_grid_search(X_train, y_train)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mbest params:\u001b[39m\u001b[33m\"\u001b[39m, best_params)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# simple back‑test (use your own test split or walk‑forward logic if you prefer)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# hyper‑parameter search\n",
    "best_params, best_model = run_grid_search(X_train, y_train)\n",
    "print(\"best params:\", best_params)\n",
    "\n",
    "# simple back‑test (use your own test split or walk‑forward logic if you prefer)\n",
    "results = run_backtest(best_model, X_train, y_train)\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f76f411c-8571-4a5a-85a5-a704faf6ce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-28 16:23:26,877] A new study created in memory with name: no-name-5371892f-0f14-4a65-b08a-7ef652c09eef\n",
      "[I 2025-07-28 16:23:30,984] Trial 0 finished with value: 0.0 and parameters: {'n': 100, 'd': 7, 'leaf': 1, 'xgb_n': 100, 'xgb_lr': 0.08399494596303467, 'xgb_subsample': 0.77458600737029, 'lgb_n': 350, 'lgb_lr': 0.03300694806652729, 'lgb_subsample': 0.912411387241534}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:23:35,096] Trial 1 finished with value: 0.0 and parameters: {'n': 300, 'd': 14, 'leaf': 1, 'xgb_n': 450, 'xgb_lr': 0.1581212158920422, 'xgb_subsample': 0.7052248777190286, 'lgb_n': 300, 'lgb_lr': 0.12416320488073383, 'lgb_subsample': 0.9025618918674194}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:23:39,217] Trial 2 finished with value: 0.0 and parameters: {'n': 500, 'd': 8, 'leaf': 1, 'xgb_n': 300, 'xgb_lr': 0.012773197281132562, 'xgb_subsample': 0.8735412918684983, 'lgb_n': 400, 'lgb_lr': 0.04754392493024487, 'lgb_subsample': 0.6709797770242928}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:23:43,497] Trial 3 finished with value: 0.0 and parameters: {'n': 400, 'd': 14, 'leaf': 1, 'xgb_n': 250, 'xgb_lr': 0.027046214488457412, 'xgb_subsample': 0.5669222496658601, 'lgb_n': 350, 'lgb_lr': 0.011636588964947518, 'lgb_subsample': 0.7097116710704349}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:23:48,072] Trial 4 finished with value: 0.0 and parameters: {'n': 200, 'd': 12, 'leaf': 4, 'xgb_n': 500, 'xgb_lr': 0.15764534253736082, 'xgb_subsample': 0.5872695905795776, 'lgb_n': 500, 'lgb_lr': 0.028762947081155316, 'lgb_subsample': 0.8673366621696414}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:23:52,552] Trial 5 finished with value: 0.0 and parameters: {'n': 200, 'd': 8, 'leaf': 4, 'xgb_n': 250, 'xgb_lr': 0.2220087862209336, 'xgb_subsample': 0.9236245878600714, 'lgb_n': 300, 'lgb_lr': 0.10216941021368801, 'lgb_subsample': 0.9113347670125166}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:23:56,974] Trial 6 finished with value: 0.0 and parameters: {'n': 200, 'd': 13, 'leaf': 3, 'xgb_n': 450, 'xgb_lr': 0.028681259960424553, 'xgb_subsample': 0.7480579140551948, 'lgb_n': 100, 'lgb_lr': 0.033733841946334116, 'lgb_subsample': 0.7408791902694746}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:01,764] Trial 7 finished with value: 0.0 and parameters: {'n': 500, 'd': 11, 'leaf': 3, 'xgb_n': 350, 'xgb_lr': 0.2562999018154601, 'xgb_subsample': 0.692839446142011, 'lgb_n': 200, 'lgb_lr': 0.028513290026177515, 'lgb_subsample': 0.532993144183252}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:06,208] Trial 8 finished with value: 0.0 and parameters: {'n': 200, 'd': 6, 'leaf': 4, 'xgb_n': 400, 'xgb_lr': 0.03258662570481341, 'xgb_subsample': 0.5975751032659911, 'lgb_n': 400, 'lgb_lr': 0.021396844666520153, 'lgb_subsample': 0.9260455915272676}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:10,431] Trial 9 finished with value: 0.0 and parameters: {'n': 400, 'd': 16, 'leaf': 2, 'xgb_n': 300, 'xgb_lr': 0.013309952072975634, 'xgb_subsample': 0.5870072562739864, 'lgb_n': 350, 'lgb_lr': 0.1219020218143091, 'lgb_subsample': 0.5876888002632212}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:14,774] Trial 10 finished with value: 0.0 and parameters: {'n': 100, 'd': 19, 'leaf': 2, 'xgb_n': 100, 'xgb_lr': 0.06778956186367634, 'xgb_subsample': 0.839621689828371, 'lgb_n': 500, 'lgb_lr': 0.21320197391656384, 'lgb_subsample': 0.8104620684690463}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:18,921] Trial 11 finished with value: 0.0 and parameters: {'n': 100, 'd': 17, 'leaf': 1, 'xgb_n': 100, 'xgb_lr': 0.09293874923982211, 'xgb_subsample': 0.7068978568863302, 'lgb_n': 250, 'lgb_lr': 0.0849470391384261, 'lgb_subsample': 0.9889017867950864}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:23,063] Trial 12 finished with value: 0.0 and parameters: {'n': 300, 'd': 10, 'leaf': 2, 'xgb_n': 200, 'xgb_lr': 0.12028394475735417, 'xgb_subsample': 0.7973860735285, 'lgb_n': 200, 'lgb_lr': 0.2822576637594633, 'lgb_subsample': 0.993475012033653}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:27,266] Trial 13 finished with value: 0.0 and parameters: {'n': 300, 'd': 5, 'leaf': 1, 'xgb_n': 500, 'xgb_lr': 0.054196520567446255, 'xgb_subsample': 0.6832085441431042, 'lgb_n': 300, 'lgb_lr': 0.07488056230044729, 'lgb_subsample': 0.8282942696572501}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:31,575] Trial 14 finished with value: 0.0 and parameters: {'n': 100, 'd': 15, 'leaf': 2, 'xgb_n': 150, 'xgb_lr': 0.15189068103259928, 'xgb_subsample': 0.7856539352256469, 'lgb_n': 400, 'lgb_lr': 0.13922407074200732, 'lgb_subsample': 0.907190012631147}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:35,795] Trial 15 finished with value: 0.0 and parameters: {'n': 400, 'd': 20, 'leaf': 1, 'xgb_n': 400, 'xgb_lr': 0.07746025339964202, 'xgb_subsample': 0.9723655125348218, 'lgb_n': 200, 'lgb_lr': 0.057738246998887466, 'lgb_subsample': 0.8008028082392197}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:40,101] Trial 16 finished with value: 0.0 and parameters: {'n': 300, 'd': 9, 'leaf': 1, 'xgb_n': 200, 'xgb_lr': 0.052964101735949655, 'xgb_subsample': 0.5106226148853166, 'lgb_n': 100, 'lgb_lr': 0.013786656047787366, 'lgb_subsample': 0.9477339040733266}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:44,339] Trial 17 finished with value: 0.0 and parameters: {'n': 100, 'd': 18, 'leaf': 3, 'xgb_n': 400, 'xgb_lr': 0.1830490445722404, 'xgb_subsample': 0.6587091438953271, 'lgb_n': 450, 'lgb_lr': 0.048754119744213925, 'lgb_subsample': 0.8701360372837655}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:48,685] Trial 18 finished with value: 0.0 and parameters: {'n': 300, 'd': 13, 'leaf': 2, 'xgb_n': 350, 'xgb_lr': 0.12920285448967744, 'xgb_subsample': 0.7509528693406127, 'lgb_n': 250, 'lgb_lr': 0.17102510107171248, 'lgb_subsample': 0.6411948721095462}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:53,448] Trial 19 finished with value: 0.0 and parameters: {'n': 200, 'd': 11, 'leaf': 1, 'xgb_n': 150, 'xgb_lr': 0.2943494158170589, 'xgb_subsample': 0.8424892795006697, 'lgb_n': 350, 'lgb_lr': 0.01514512175231626, 'lgb_subsample': 0.7798342549880936}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:24:58,061] Trial 20 finished with value: 0.0 and parameters: {'n': 400, 'd': 7, 'leaf': 2, 'xgb_n': 450, 'xgb_lr': 0.1066181635330458, 'xgb_subsample': 0.6478662688490695, 'lgb_n': 300, 'lgb_lr': 0.06721707577726296, 'lgb_subsample': 0.8573198767747124}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:02,965] Trial 21 finished with value: 0.0 and parameters: {'n': 500, 'd': 8, 'leaf': 1, 'xgb_n': 300, 'xgb_lr': 0.014147658209995306, 'xgb_subsample': 0.8560112357366539, 'lgb_n': 400, 'lgb_lr': 0.03669467901436954, 'lgb_subsample': 0.6825846991414118}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:07,427] Trial 22 finished with value: 0.0 and parameters: {'n': 500, 'd': 5, 'leaf': 1, 'xgb_n': 250, 'xgb_lr': 0.019968095548803473, 'xgb_subsample': 0.901226217983749, 'lgb_n': 400, 'lgb_lr': 0.04655101492222713, 'lgb_subsample': 0.6472899356538163}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:11,773] Trial 23 finished with value: 0.0 and parameters: {'n': 500, 'd': 9, 'leaf': 1, 'xgb_n': 350, 'xgb_lr': 0.010083584117226773, 'xgb_subsample': 0.7837968927607957, 'lgb_n': 450, 'lgb_lr': 0.019730666755757492, 'lgb_subsample': 0.7470018315443436}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:16,885] Trial 24 finished with value: 0.0 and parameters: {'n': 400, 'd': 7, 'leaf': 1, 'xgb_n': 450, 'xgb_lr': 0.04253790447668374, 'xgb_subsample': 0.8895613417023869, 'lgb_n': 450, 'lgb_lr': 0.041829668155983414, 'lgb_subsample': 0.5483104021582925}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:21,506] Trial 25 finished with value: 0.0 and parameters: {'n': 300, 'd': 15, 'leaf': 2, 'xgb_n': 150, 'xgb_lr': 0.08839925127106191, 'xgb_subsample': 0.9978825838175399, 'lgb_n': 250, 'lgb_lr': 0.09628886594952742, 'lgb_subsample': 0.6123479100816003}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:25,858] Trial 26 finished with value: 0.0 and parameters: {'n': 300, 'd': 11, 'leaf': 1, 'xgb_n': 200, 'xgb_lr': 0.04400460768144638, 'xgb_subsample': 0.7391804941643377, 'lgb_n': 350, 'lgb_lr': 0.05831500156438566, 'lgb_subsample': 0.9552849270163276}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:30,382] Trial 27 finished with value: 0.0 and parameters: {'n': 200, 'd': 7, 'leaf': 2, 'xgb_n': 300, 'xgb_lr': 0.06612296028023908, 'xgb_subsample': 0.8201220361843699, 'lgb_n': 300, 'lgb_lr': 0.021869195512800817, 'lgb_subsample': 0.6916988445451511}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:34,681] Trial 28 finished with value: 0.0 and parameters: {'n': 400, 'd': 9, 'leaf': 1, 'xgb_n': 500, 'xgb_lr': 0.20150153509014865, 'xgb_subsample': 0.9373493789946863, 'lgb_n': 350, 'lgb_lr': 0.028129573472599555, 'lgb_subsample': 0.8501501114240827}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:39,083] Trial 29 finished with value: 0.0 and parameters: {'n': 500, 'd': 14, 'leaf': 1, 'xgb_n': 250, 'xgb_lr': 0.01789452489496702, 'xgb_subsample': 0.8742277785517086, 'lgb_n': 400, 'lgb_lr': 0.1558700163850595, 'lgb_subsample': 0.7191857837907966}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:43,599] Trial 30 finished with value: 0.0 and parameters: {'n': 100, 'd': 6, 'leaf': 3, 'xgb_n': 100, 'xgb_lr': 0.022606636911935752, 'xgb_subsample': 0.6314933585904102, 'lgb_n': 450, 'lgb_lr': 0.010474338409067144, 'lgb_subsample': 0.7743482285411118}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:48,274] Trial 31 finished with value: 0.0 and parameters: {'n': 400, 'd': 12, 'leaf': 1, 'xgb_n': 250, 'xgb_lr': 0.02935785785147595, 'xgb_subsample': 0.5220113824929539, 'lgb_n': 350, 'lgb_lr': 0.010163112135978258, 'lgb_subsample': 0.6953649404261323}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:52,810] Trial 32 finished with value: 0.0 and parameters: {'n': 400, 'd': 14, 'leaf': 1, 'xgb_n': 350, 'xgb_lr': 0.03909405259678422, 'xgb_subsample': 0.5648153751417404, 'lgb_n': 300, 'lgb_lr': 0.014505360861482327, 'lgb_subsample': 0.6574538991446613}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:25:57,152] Trial 33 finished with value: 0.0 and parameters: {'n': 500, 'd': 12, 'leaf': 1, 'xgb_n': 200, 'xgb_lr': 0.023560503600143803, 'xgb_subsample': 0.7210002650114551, 'lgb_n': 350, 'lgb_lr': 0.033132161005972105, 'lgb_subsample': 0.8822502272027051}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:01,522] Trial 34 finished with value: 0.0 and parameters: {'n': 500, 'd': 14, 'leaf': 4, 'xgb_n': 300, 'xgb_lr': 0.010661801555816272, 'xgb_subsample': 0.5606595864456593, 'lgb_n': 500, 'lgb_lr': 0.02660053315931782, 'lgb_subsample': 0.7245522113795329}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:05,778] Trial 35 finished with value: 0.0 and parameters: {'n': 400, 'd': 16, 'leaf': 1, 'xgb_n': 300, 'xgb_lr': 0.16325135321925252, 'xgb_subsample': 0.7561461581569624, 'lgb_n': 250, 'lgb_lr': 0.11922766734708923, 'lgb_subsample': 0.5850876708650338}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:10,072] Trial 36 finished with value: 0.0 and parameters: {'n': 200, 'd': 10, 'leaf': 2, 'xgb_n': 400, 'xgb_lr': 0.014818513202393274, 'xgb_subsample': 0.6097297815684446, 'lgb_n': 400, 'lgb_lr': 0.07008610285261643, 'lgb_subsample': 0.8906903787629342}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:14,428] Trial 37 finished with value: 0.0 and parameters: {'n': 500, 'd': 13, 'leaf': 3, 'xgb_n': 250, 'xgb_lr': 0.033647039843173236, 'xgb_subsample': 0.930926999386978, 'lgb_n': 300, 'lgb_lr': 0.017257834236517305, 'lgb_subsample': 0.768490870873584}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:18,636] Trial 38 finished with value: 0.0 and parameters: {'n': 200, 'd': 16, 'leaf': 1, 'xgb_n': 350, 'xgb_lr': 0.22819640884303743, 'xgb_subsample': 0.8207777955316445, 'lgb_n': 350, 'lgb_lr': 0.03790441620655789, 'lgb_subsample': 0.9341081084584467}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:22,998] Trial 39 finished with value: 0.0 and parameters: {'n': 300, 'd': 8, 'leaf': 2, 'xgb_n': 150, 'xgb_lr': 0.01640747013320485, 'xgb_subsample': 0.6819804634896331, 'lgb_n': 300, 'lgb_lr': 0.21415540044006806, 'lgb_subsample': 0.9714440606427253}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:27,347] Trial 40 finished with value: 0.0 and parameters: {'n': 400, 'd': 17, 'leaf': 1, 'xgb_n': 450, 'xgb_lr': 0.012616440586046572, 'xgb_subsample': 0.5537499218055462, 'lgb_n': 400, 'lgb_lr': 0.022720008038675996, 'lgb_subsample': 0.8270059129748628}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:31,581] Trial 41 finished with value: 0.0 and parameters: {'n': 100, 'd': 15, 'leaf': 4, 'xgb_n': 500, 'xgb_lr': 0.14971596317887595, 'xgb_subsample': 0.6149086618528281, 'lgb_n': 500, 'lgb_lr': 0.03323062103962149, 'lgb_subsample': 0.9188792669552471}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:35,779] Trial 42 finished with value: 0.0 and parameters: {'n': 200, 'd': 6, 'leaf': 4, 'xgb_n': 500, 'xgb_lr': 0.11822476090178549, 'xgb_subsample': 0.5369091891496993, 'lgb_n': 500, 'lgb_lr': 0.050035389658285696, 'lgb_subsample': 0.9027200511114088}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:39,998] Trial 43 finished with value: 0.0 and parameters: {'n': 200, 'd': 10, 'leaf': 3, 'xgb_n': 450, 'xgb_lr': 0.07067677224240983, 'xgb_subsample': 0.5773746496102665, 'lgb_n': 450, 'lgb_lr': 0.02618023343537073, 'lgb_subsample': 0.8375294386361444}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:44,487] Trial 44 finished with value: 0.0 and parameters: {'n': 100, 'd': 12, 'leaf': 4, 'xgb_n': 400, 'xgb_lr': 0.096355020999163, 'xgb_subsample': 0.7015655556791462, 'lgb_n': 250, 'lgb_lr': 0.0848578582244171, 'lgb_subsample': 0.7285007557673114}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:49,022] Trial 45 finished with value: 0.0 and parameters: {'n': 300, 'd': 13, 'leaf': 2, 'xgb_n': 100, 'xgb_lr': 0.1345530845137377, 'xgb_subsample': 0.6602589522706003, 'lgb_n': 350, 'lgb_lr': 0.030297856814103415, 'lgb_subsample': 0.8052900092515398}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:53,441] Trial 46 finished with value: 0.0 and parameters: {'n': 300, 'd': 8, 'leaf': 3, 'xgb_n': 500, 'xgb_lr': 0.17764506505335306, 'xgb_subsample': 0.5953716900334466, 'lgb_n': 150, 'lgb_lr': 0.011780583188091531, 'lgb_subsample': 0.9998713969395354}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:26:58,039] Trial 47 finished with value: 0.0 and parameters: {'n': 100, 'd': 11, 'leaf': 1, 'xgb_n': 200, 'xgb_lr': 0.24864630908018026, 'xgb_subsample': 0.6725302142131047, 'lgb_n': 450, 'lgb_lr': 0.05983151162656171, 'lgb_subsample': 0.9649461052815034}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:27:02,231] Trial 48 finished with value: 0.0 and parameters: {'n': 200, 'd': 14, 'leaf': 1, 'xgb_n': 400, 'xgb_lr': 0.02644138642969355, 'xgb_subsample': 0.798171077462384, 'lgb_n': 350, 'lgb_lr': 0.04317879745170636, 'lgb_subsample': 0.5057036150177467}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-07-28 16:27:06,401] Trial 49 finished with value: 0.0 and parameters: {'n': 100, 'd': 17, 'leaf': 2, 'xgb_n': 350, 'xgb_lr': 0.08511248630959492, 'xgb_subsample': 0.6363765787912187, 'lgb_n': 300, 'lgb_lr': 0.1039510247308286, 'lgb_subsample': 0.934053806924677}. Best is trial 0 with value: 0.0.\n"
     ]
    }
   ],
   "source": [
    "# Cell GS (long‑running but silent)\n",
    "import contextlib, io\n",
    "\n",
    "buf = io.StringIO()                       # buffer to swallow stdout/stderr\n",
    "with contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf):\n",
    "    run_grid_search(X_train, y_train)     # no unpacking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50801fa3-51f3-4363-82e1-6d4633764735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ best params: {'d': 7, 'leaf': 1, 'lgb_lr': 0.03300694806652729, 'lgb_n': 350, 'lgb_subsample': 0.912411387241534, 'n': 100, 'xgb_lr': 0.08399494596303467, 'xgb_n': 100, 'xgb_subsample': 0.77458600737029}\n",
      "🔥 model fitted\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot include dtype 'M' in a buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     54\u001b[39m proba  = best_model.predict_proba(X_train)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     55\u001b[39m signal = (proba > \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     57\u001b[39m close_px = (\u001b[43mdf_prices\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mClose\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43m            \u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx_dates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m             .ffill()\n\u001b[32m     60\u001b[39m             .values)\n\u001b[32m     62\u001b[39m bt_data = pd.DataFrame({\n\u001b[32m     63\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m       : idx_dates,          \u001b[38;5;66;03m# already datetime64\u001b[39;00m\n\u001b[32m     64\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSymbol\u001b[39m\u001b[33m\"\u001b[39m     : TICKER,\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mProbability\u001b[39m\u001b[33m\"\u001b[39m: proba\n\u001b[32m     68\u001b[39m })\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# --- 5. save artefact --------------------------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\pandas\\core\\series.py:5164\u001b[39m, in \u001b[36mSeries.reindex\u001b[39m\u001b[34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5147\u001b[39m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[32m   5148\u001b[39m     NDFrame.reindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m   5149\u001b[39m     klass=_shared_doc_kwargs[\u001b[33m\"\u001b[39m\u001b[33mklass\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   5162\u001b[39m     tolerance=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5163\u001b[39m ) -> Series:\n\u001b[32m-> \u001b[39m\u001b[32m5164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\pandas\\core\\generic.py:5629\u001b[39m, in \u001b[36mNDFrame.reindex\u001b[39m\u001b[34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[39m\n\u001b[32m   5626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._reindex_multi(axes, copy, fill_value)\n\u001b[32m   5628\u001b[39m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5629\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5630\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m   5631\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mreindex\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\pandas\\core\\generic.py:5652\u001b[39m, in \u001b[36mNDFrame._reindex_axes\u001b[39m\u001b[34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[39m\n\u001b[32m   5649\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   5651\u001b[39m ax = \u001b[38;5;28mself\u001b[39m._get_axis(a)\n\u001b[32m-> \u001b[39m\u001b[32m5652\u001b[39m new_index, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[32m   5654\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5656\u001b[39m axis = \u001b[38;5;28mself\u001b[39m._get_axis_number(a)\n\u001b[32m   5657\u001b[39m obj = obj._reindex_with_indexers(\n\u001b[32m   5658\u001b[39m     {axis: [new_index, indexer]},\n\u001b[32m   5659\u001b[39m     fill_value=fill_value,\n\u001b[32m   5660\u001b[39m     copy=copy,\n\u001b[32m   5661\u001b[39m     allow_dups=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   5662\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4440\u001b[39m, in \u001b[36mIndex.reindex\u001b[39m\u001b[34m(self, target, method, level, limit, tolerance)\u001b[39m\n\u001b[32m   4437\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4438\u001b[39m             indexer, _ = \u001b[38;5;28mself\u001b[39m.get_indexer_non_unique(target)\n\u001b[32m-> \u001b[39m\u001b[32m4440\u001b[39m target = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrap_reindex_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4441\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m target, indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2736\u001b[39m, in \u001b[36mMultiIndex._wrap_reindex_result\u001b[39m\u001b[34m(self, target, indexer, preserve_names)\u001b[39m\n\u001b[32m   2734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2735\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2736\u001b[39m         target = \u001b[43mMultiIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_tuples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2737\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   2738\u001b[39m         \u001b[38;5;66;03m# not all tuples, see test_constructor_dict_multiindex_reindex_flat\u001b[39;00m\n\u001b[32m   2739\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:223\u001b[39m, in \u001b[36mnames_compat.<locals>.new_meth\u001b[39m\u001b[34m(self_or_cls, *args, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    221\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_or_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\market-predictions\\.venv312\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:618\u001b[39m, in \u001b[36mMultiIndex.from_tuples\u001b[39m\u001b[34m(cls, tuples, sortorder, names)\u001b[39m\n\u001b[32m    615\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tuples, Index):\n\u001b[32m    616\u001b[39m         tuples = np.asarray(tuples._values)\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m     arrays = \u001b[38;5;28mlist\u001b[39m(\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtuples_to_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuples\u001b[49m\u001b[43m)\u001b[49m.T)\n\u001b[32m    619\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tuples, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    620\u001b[39m     arrays = \u001b[38;5;28mlist\u001b[39m(lib.to_object_array_tuples(tuples).T)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:3056\u001b[39m, in \u001b[36mpandas._libs.lib.tuples_to_object_array\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: cannot include dtype 'M' in a buffer"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Cell: build best model ➜ create artefact ➜ vectorbt back‑test\n",
    "# ---------------------------------------------------------------\n",
    "import pandas as pd, joblib, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost  import XGBClassifier\n",
    "\n",
    "# --- sanity checks ------------------------------------------------\n",
    "assert \"X_train\" in globals() and \"y_train\" in globals(), \"Run feature‑eng cell first\"\n",
    "assert \"df_prices\" in globals(), \"df_prices must be loaded\"\n",
    "\n",
    "TICKER = \"AAPL\"   # change if you trained on another symbol\n",
    "\n",
    "# --- 1. load Optuna table & pull best params ----------------------\n",
    "best_row = (\n",
    "    pd.read_parquet(\"grid_search_results.parquet\")\n",
    "      .sort_values(\"value\", ascending=False)\n",
    "      .iloc[0]\n",
    ")\n",
    "best_params = {k.replace(\"params_\", \"\"): best_row[k]\n",
    "               for k in best_row.index if k.startswith(\"params_\")}\n",
    "print(\"✅ best params:\", best_params)\n",
    "\n",
    "# --- 2. fit the winning model ------------------------------------\n",
    "if any(k.startswith(\"lgb_\") for k in best_row.index):\n",
    "    clean = {k.replace(\"lgb_\", \"\"): v\n",
    "             for k, v in best_params.items() if k.startswith(\"lgb_\")}\n",
    "    best_model = LGBMClassifier(**clean).fit(X_train, y_train)\n",
    "\n",
    "elif any(k.startswith(\"xgb_\") for k in best_row.index):\n",
    "    clean = {k.replace(\"xgb_\", \"\"): v\n",
    "             for k, v in best_params.items() if k.startswith(\"xgb_\")}\n",
    "    best_model = XGBClassifier(use_label_encoder=False,\n",
    "                               eval_metric=\"logloss\",\n",
    "                               **clean).fit(X_train, y_train)\n",
    "else:\n",
    "    rf_keys = RandomForestClassifier().get_params()\n",
    "    clean   = {k: v for k, v in best_params.items() if k in rf_keys}\n",
    "    best_model = RandomForestClassifier(**clean).fit(X_train, y_train)\n",
    "\n",
    "print(\"🔥 model fitted\")\n",
    "\n",
    "# --- 3. locate the date level of the MultiIndex ------------------\n",
    "for lev in range(X_train.index.nlevels):\n",
    "    if np.issubdtype(X_train.index.get_level_values(lev).dtype, np.datetime64):\n",
    "        idx_dates = X_train.index.get_level_values(lev)\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"Could not find datetime level in X_train index\")\n",
    "\n",
    "# --- 4. build bt_data --------------------------------------------\n",
    "proba  = best_model.predict_proba(X_train)[:, 1]\n",
    "signal = (proba > 0.5).astype(int)\n",
    "\n",
    "close_px = (df_prices[\"Close\"]\n",
    "            .reindex(idx_dates)\n",
    "            .ffill()\n",
    "            .values)\n",
    "\n",
    "bt_data = pd.DataFrame({\n",
    "        \"Date\"       : idx_dates,          # already datetime64\n",
    "        \"Symbol\"     : TICKER,\n",
    "        \"Close\"      : close_px,\n",
    "        \"Predicted\"  : signal,\n",
    "        \"Probability\": proba\n",
    "})\n",
    "\n",
    "# --- 5. save artefact --------------------------------------------\n",
    "art_path = Path(\"best_model.joblib\")\n",
    "artefact = {\n",
    "    \"model\"    : best_model,\n",
    "    \"features\" : X_train.columns.tolist(),\n",
    "    \"bt_data\"  : bt_data\n",
    "}\n",
    "joblib.dump(artefact, art_path)\n",
    "print(\"📦 artefact saved to\", art_path)\n",
    "\n",
    "# --- 6. run vectorbt back‑test -----------------------------------\n",
    "results = run_backtest(art_path)      # helper expects only the Path\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e06049-4c3c-4da1-a189-7c086395d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
